{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "748702ca",
   "metadata": {},
   "source": [
    " ### **Question C | Extreme Value Theory**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ec6cbe",
   "metadata": {},
   "source": [
    ">With the dataset provided for TD1 on Natixis prices, first calculate daily returns. You will then analyse\n",
    "these returns using a specific method in the field of the EVT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e664e295",
   "metadata": {},
   "source": [
    ">a – Estimate the GEV parameters for the two tails of the distribution of returns, using the estimator of\n",
    "Pickands. What can you conclude about the nature of the extreme gains and losses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92199694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47e9bc6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02/01/2015</td>\n",
       "      <td>5,621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/01/2015</td>\n",
       "      <td>5,424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06/01/2015</td>\n",
       "      <td>5,329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07/01/2015</td>\n",
       "      <td>5,224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/01/2015</td>\n",
       "      <td>5,453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Price\n",
       "0  02/01/2015  5,621\n",
       "1  05/01/2015  5,424\n",
       "2  06/01/2015  5,329\n",
       "3  07/01/2015  5,224\n",
       "4  08/01/2015  5,453"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We load the data \n",
    "df = pd.read_csv(\"Natixis Stock.csv\", header=None, sep=r\"\\s+\", names=[\"Date\", \"Price\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c83f7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing dates correctly and handling the decimal format\n",
    "df[\"Date\"]=pd.to_datetime(df[\"Date\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "df[\"Price\"]=df[\"Price\"].str.replace(\",\",\".\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d28dd197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Price\n",
      "0 2015-01-02  5.621\n",
      "1 2015-01-05  5.424\n",
      "2 2015-01-06  5.329\n",
      "3 2015-01-07  5.224\n",
      "4 2015-01-08  5.453\n",
      "           Date  Price\n",
      "1018 2018-12-21  4.045\n",
      "1019 2018-12-24  4.010\n",
      "1020 2018-12-27  3.938\n",
      "1021 2018-12-28  4.088\n",
      "1022 2018-12-31  4.119\n",
      "                                Date        Price\n",
      "count                           1023  1023.000000\n",
      "mean   2016-12-30 10:54:32.727272704     5.684600\n",
      "min              2015-01-02 00:00:00     3.077000\n",
      "25%              2016-01-02 00:00:00     4.927000\n",
      "50%              2016-12-29 00:00:00     5.782000\n",
      "75%              2017-12-28 12:00:00     6.532000\n",
      "max              2018-12-31 00:00:00     7.744000\n",
      "std                              NaN     1.021034\n",
      "Number of NaN price: 0\n",
      "Number of NaN price: 0\n"
     ]
    }
   ],
   "source": [
    "#Some informations about the dataset\n",
    "print(df.head(5))\n",
    "print(df.tail(5))\n",
    "print(df.describe())\n",
    "#Verification of data\n",
    "print(\"Number of NaN price:\", df[\"Price\"].isna().sum())\n",
    "print(\"Number of NaN price:\", df[\"Date\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a4cb987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>5.424</td>\n",
       "      <td>-0.035047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>5.329</td>\n",
       "      <td>-0.017515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>5.224</td>\n",
       "      <td>-0.019704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>5.453</td>\n",
       "      <td>0.043836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>5.340</td>\n",
       "      <td>-0.020723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>4.045</td>\n",
       "      <td>-0.001481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>2018-12-24</td>\n",
       "      <td>4.010</td>\n",
       "      <td>-0.008653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>3.938</td>\n",
       "      <td>-0.017955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>4.088</td>\n",
       "      <td>0.038090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>4.119</td>\n",
       "      <td>0.007583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Price    return\n",
       "1    2015-01-05  5.424 -0.035047\n",
       "2    2015-01-06  5.329 -0.017515\n",
       "3    2015-01-07  5.224 -0.019704\n",
       "4    2015-01-08  5.453  0.043836\n",
       "5    2015-01-09  5.340 -0.020723\n",
       "...         ...    ...       ...\n",
       "1018 2018-12-21  4.045 -0.001481\n",
       "1019 2018-12-24  4.010 -0.008653\n",
       "1020 2018-12-27  3.938 -0.017955\n",
       "1021 2018-12-28  4.088  0.038090\n",
       "1022 2018-12-31  4.119  0.007583\n",
       "\n",
       "[1022 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"return\"]=df[\"Price\"].pct_change() \n",
    "df = df.iloc[1:] #Del the Nan values of the first row\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad233550",
   "metadata": {},
   "source": [
    "To estimate $\\xi$, we use the Pickands Estimator. This estimator is based on order statistics, where $X_{1:n} \\le X_{2:n} \\le \\dots \\le X_{n:n}$ are the sorted observations.\n",
    "\n",
    "For a given threshold parameter $k$, the Pickands estimator is defined as:\n",
    "\n",
    "$$\\hat{\\xi}_P(k) = \\frac{1}{\\log(2)} \\log \\left( \\frac{X_{n-k+1:n} - X_{n-2k+1:n}}{X_{n-2k+1:n} - X_{n-4k+1:n}} \\right)$$\n",
    "\n",
    "Where:\n",
    "* $n$ the  number of observations\n",
    "* $X_{n-k+1:n}$ corresponds to the $k$-th largest value\n",
    "* $k \\to \\infty$ and $k/n \\to 0$ as $n \\to \\infty$\n",
    "\n",
    "\n",
    "Once the parameter find, we will be able to establish the nature of the tails:\n",
    "* $\\xi > 0$, the GEV is of Fréchet kind : Heavy tail, typical for financial returns\n",
    "* $\\xi = 0$, the GEV is of Gumbel kind: Thin tails, for normal or exponential distributions\n",
    "* $\\xi < 0$, the GEV is of Weibull kind: Short/bounded tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6062ffcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot perform __mul__ with this index type: DatetimeArray",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m sorted_returns = df.sort_values(by=\u001b[33m'\u001b[39m\u001b[33mreturn\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m returns_negative= \u001b[43msorted_returns\u001b[49m\u001b[43m[\u001b[49m\u001b[43msorted_returns\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mreturn\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m<\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m*\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# On prends la queue de distribution des pertes, on multiplie par -1 pr les avoirs en positif\u001b[39;00m\n\u001b[32m      5\u001b[39m returns_negative = returns_negative.sort_values(by=\u001b[33m'\u001b[39m\u001b[33mreturn\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      7\u001b[39m returns_positive= sorted_returns[sorted_returns[\u001b[33m'\u001b[39m\u001b[33mreturn\u001b[39m\u001b[33m'\u001b[39m] > \u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Msi Gaming\\Desktop\\ESILV\\A4_Finance\\Cours\\ML\\Final_LAB\\venv\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Msi Gaming\\Desktop\\ESILV\\A4_Finance\\Cours\\ML\\Final_LAB\\venv\\Lib\\site-packages\\pandas\\core\\arraylike.py:202\u001b[39m, in \u001b[36mOpsMixin.__mul__\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m    200\u001b[39m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m__mul__\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmul\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Msi Gaming\\Desktop\\ESILV\\A4_Finance\\Cours\\ML\\Final_LAB\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:7935\u001b[39m, in \u001b[36mDataFrame._arith_method\u001b[39m\u001b[34m(self, other, op)\u001b[39m\n\u001b[32m   7932\u001b[39m \u001b[38;5;28mself\u001b[39m, other = \u001b[38;5;28mself\u001b[39m._align_for_op(other, axis, flex=\u001b[38;5;28;01mTrue\u001b[39;00m, level=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   7934\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(\u001b[38;5;28mall\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m7935\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dispatch_frame_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7936\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._construct_result(new_data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Msi Gaming\\Desktop\\ESILV\\A4_Finance\\Cours\\ML\\Final_LAB\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:7967\u001b[39m, in \u001b[36mDataFrame._dispatch_frame_op\u001b[39m\u001b[34m(self, right, func, axis)\u001b[39m\n\u001b[32m   7964\u001b[39m right = lib.item_from_zerodim(right)\n\u001b[32m   7965\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(right):\n\u001b[32m   7966\u001b[39m     \u001b[38;5;66;03m# i.e. scalar, faster than checking np.ndim(right) == 0\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m7967\u001b[39m     bm = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m=\u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7968\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(bm, axes=bm.axes)\n\u001b[32m   7970\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, DataFrame):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Msi Gaming\\Desktop\\ESILV\\A4_Finance\\Cours\\ML\\Final_LAB\\venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:361\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    358\u001b[39m             kwargs[k] = obj[b.mgr_locs.indexer]\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(f):\n\u001b[32m--> \u001b[39m\u001b[32m361\u001b[39m     applied = \u001b[43mb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    363\u001b[39m     applied = \u001b[38;5;28mgetattr\u001b[39m(b, f)(**kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Msi Gaming\\Desktop\\ESILV\\A4_Finance\\Cours\\ML\\Final_LAB\\venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:395\u001b[39m, in \u001b[36mBlock.apply\u001b[39m\u001b[34m(self, func, **kwargs)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, **kwargs) -> \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[32m    391\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    392\u001b[39m \u001b[33;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[32m    393\u001b[39m \u001b[33;03m    one\u001b[39;00m\n\u001b[32m    394\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    397\u001b[39m     result = maybe_coerce_values(result)\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._split_op_result(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Msi Gaming\\Desktop\\ESILV\\A4_Finance\\Cours\\ML\\Final_LAB\\venv\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:273\u001b[39m, in \u001b[36marithmetic_op\u001b[39m\u001b[34m(left, right, op)\u001b[39m\n\u001b[32m    260\u001b[39m \u001b[38;5;66;03m# NB: We assume that extract_array and ensure_wrapped_if_datetimelike\u001b[39;00m\n\u001b[32m    261\u001b[39m \u001b[38;5;66;03m#  have already been called on `left` and `right`,\u001b[39;00m\n\u001b[32m    262\u001b[39m \u001b[38;5;66;03m#  and `maybe_prepare_scalar_for_op` has already been called on `right`\u001b[39;00m\n\u001b[32m    263\u001b[39m \u001b[38;5;66;03m# We need to special-case datetime64/timedelta64 dtypes (e.g. because numpy\u001b[39;00m\n\u001b[32m    264\u001b[39m \u001b[38;5;66;03m# casts integer dtypes to timedelta64 when operating with timedelta64 - GH#22390)\u001b[39;00m\n\u001b[32m    266\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    267\u001b[39m     should_extension_dispatch(left, right)\n\u001b[32m    268\u001b[39m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, (Timedelta, BaseOffset, Timestamp))\n\u001b[32m   (...)\u001b[39m\u001b[32m    271\u001b[39m     \u001b[38;5;66;03m# Timedelta/Timestamp and other custom scalars are included in the check\u001b[39;00m\n\u001b[32m    272\u001b[39m     \u001b[38;5;66;03m# because numexpr will fail on it, see GH#31457\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m     res_values = op(left, right)\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    275\u001b[39m     \u001b[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001b[39;00m\n\u001b[32m    276\u001b[39m     \u001b[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001b[39;00m\n\u001b[32m    277\u001b[39m     \u001b[38;5;66;03m# error: Argument 2 to \"_bool_arith_check\" has incompatible type\u001b[39;00m\n\u001b[32m    278\u001b[39m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[32m    279\u001b[39m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Msi Gaming\\Desktop\\ESILV\\A4_Finance\\Cours\\ML\\Final_LAB\\venv\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[39m, in \u001b[36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     72\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[32m     74\u001b[39m other = item_from_zerodim(other)\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Msi Gaming\\Desktop\\ESILV\\A4_Finance\\Cours\\ML\\Final_LAB\\venv\\Lib\\site-packages\\pandas\\core\\ops\\invalid.py:59\u001b[39m, in \u001b[36mmake_invalid_op.<locals>.invalid_op\u001b[39m\u001b[34m(self, other)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvalid_op\u001b[39m(\u001b[38;5;28mself\u001b[39m, other=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     58\u001b[39m     typ = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mcannot perform \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with this index type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtyp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: cannot perform __mul__ with this index type: DatetimeArray"
     ]
    }
   ],
   "source": [
    "sorted_returns = df.sort_values(by='return', ascending=True)\n",
    "returns_negative= sorted_returns[sorted_returns['return']<0]*(-1) # On prends la queue de distribution des pertes, on multiplie par -1 pr les avoirs en positif\n",
    "returns_negative = returns_negative.sort_values(by='return', ascending=True)\n",
    "\n",
    "returns_positive= sorted_returns[sorted_returns['return'] > 0]\n",
    "\n",
    "\n",
    "def estimateur_pickands(return_sort):\n",
    "  n = len(return_sort)#revoir les indexs\n",
    "  index_1 = n - int(np.log(n))+1\n",
    "  index_2 = n - int(2 * np.log(n))+1\n",
    "  index_4 = n - int(4 * np.log(n))+1\n",
    "\n",
    "  pickands = (1 / np.log(2)) * np.log((return_sort.iloc[index_1]['return'] - return_sort.iloc[index_2]['return']) / (return_sort.iloc[index_2]['return'] - return_sort.iloc[index_4]['return']))\n",
    "\n",
    "  return pickands\n",
    "\n",
    "gev_rend_positive = estimateur_pickands(returns_positive)\n",
    "gev_rend_neg = estimateur_pickands(returns_negative)\n",
    "\n",
    "print(\"GEV Paremeters for positive returns : \", gev_rend_positive)\n",
    "print(\"GEV Parameters for negative returns : \", gev_rend_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c6b7ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation de xi (Pertes) pour k=51 : 0.3233\n",
      "Estimation de xi (Gains) pour k=51 : -0.7601\n"
     ]
    }
   ],
   "source": [
    "returns = df['return'].values\n",
    "gains = returns[returns > 0]\n",
    "losses = -returns[returns < 0]\n",
    "\n",
    "def p_estimator(data, k):\n",
    "    \"\"\"\n",
    "    Calcule l'estimateur de Pickands pour un seuil k.\n",
    "    data: tableau de données (gains ou pertes)\n",
    "    k: paramètre de seuil (4k <= n)\n",
    "    \"\"\"\n",
    "    n = len(data)\n",
    "    # Tri des données pour obtenir les statistiques d'ordre\n",
    "    sorted_data = np.sort(data)\n",
    "    \n",
    "    # Formule de Pickands (p. 180)\n",
    "    # X_{n-k+1:n} est le k-ième plus grand élément\n",
    "    index1 = sorted_data[n - k]\n",
    "    index2 = sorted_data[n - 2*k]\n",
    "    index3 = sorted_data[n - 4*k]\n",
    "    \n",
    "    numerator = val1 - val2\n",
    "    denominator = val2 - val3\n",
    "    \n",
    "    # On évite la division par zéro ou log de valeurs négatives\n",
    "    if denominator <= 0 or numerator <= 0:\n",
    "        return np.nan\n",
    "        \n",
    "    return (1 / np.log(2)) * np.log(numerator / denominator)\n",
    "\n",
    "# 3. Estimation pour différents k pour analyser la stabilité\n",
    "k_values = range(1, len(losses) // 4)\n",
    "xi_gains = [p_estimator(gains, k) for k in k_values]\n",
    "xi_losses = [p_estimator(losses, k) for k in k_values]\n",
    "\n",
    "# Affichage des résultats pour un k raisonnable (ex: 10% des données)\n",
    "k_target = int(len(losses) * 0.1)\n",
    "xi_p_losses = p_estimator(losses, k_target)\n",
    "xi_p_gains = p_estimator(gains, k_target)\n",
    "\n",
    "print(f\"Estimation de xi (Pertes) pour k={k_target} : {xi_p_losses:.4f}\")\n",
    "print(f\"Estimation de xi (Gains) pour k={k_target} : {xi_p_gains:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
