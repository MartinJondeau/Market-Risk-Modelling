{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85040c54",
   "metadata": {},
   "source": [
    " ### **Question A | Non-parametric VaR estimation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f0036d",
   "metadata": {},
   "source": [
    ">a ‚Äì From the time series of the daily prices of the stock Natixis between January 2015 and December\n",
    "2016, provided with TD1, estimate a historical VaR on price returns at a one-day horizon for a given\n",
    "probability level (this probability is a parameter which must be changed easily). You must base your\n",
    "VaR on a non-parametric distribution (biweight Kernel, that is ùêæ is the derivative of the logistic function$$K(x) = \\frac{15}{16} (1 - x^2)^2 \\mathbb{1}_{|x| \\le 1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ab9d9334",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a519b482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02/01/2015</td>\n",
       "      <td>5,621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05/01/2015</td>\n",
       "      <td>5,424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06/01/2015</td>\n",
       "      <td>5,329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07/01/2015</td>\n",
       "      <td>5,224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08/01/2015</td>\n",
       "      <td>5,453</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  Price\n",
       "0  02/01/2015  5,621\n",
       "1  05/01/2015  5,424\n",
       "2  06/01/2015  5,329\n",
       "3  07/01/2015  5,224\n",
       "4  08/01/2015  5,453"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We load the data \n",
    "df = pd.read_csv(\"Natixis Stock.csv\", header=None, sep=r\"\\s+\", names=[\"Date\", \"Price\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5eb8e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parsing dates correctly and handling the decimal format\n",
    "df[\"Date\"]=pd.to_datetime(df[\"Date\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "df[\"Price\"]=df[\"Price\"].str.replace(\",\",\".\").astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bb3b63e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date  Price    return\n",
      "1 2015-01-05  5.424 -0.035047\n",
      "2 2015-01-06  5.329 -0.017515\n",
      "3 2015-01-07  5.224 -0.019704\n",
      "4 2015-01-08  5.453  0.043836\n",
      "5 2015-01-09  5.340 -0.020723\n",
      "           Date  Price    return\n",
      "1018 2018-12-21  4.045 -0.001481\n",
      "1019 2018-12-24  4.010 -0.008653\n",
      "1020 2018-12-27  3.938 -0.017955\n",
      "1021 2018-12-28  4.088  0.038090\n",
      "1022 2018-12-31  4.119  0.007583\n",
      "                                Date        Price       return\n",
      "count                           1022  1022.000000  1022.000000\n",
      "mean   2016-12-31 04:00:56.360078336     5.684662    -0.000097\n",
      "min              2015-01-05 00:00:00     3.077000    -0.171325\n",
      "25%              2016-01-04 06:00:00     4.925500    -0.010602\n",
      "50%              2016-12-29 12:00:00     5.784000    -0.000506\n",
      "75%              2017-12-28 18:00:00     6.532500     0.011274\n",
      "max              2018-12-31 00:00:00     7.744000     0.090281\n",
      "std                              NaN     1.021532     0.020286\n",
      "Number of NaN price: 0\n",
      "Number of NaN price: 0\n"
     ]
    }
   ],
   "source": [
    "#Some informations about the dataset\n",
    "print(df.head(5))\n",
    "print(df.tail(5))\n",
    "print(df.describe())\n",
    "#Verification of data\n",
    "print(\"Number of NaN price:\", df[\"Price\"].isna().sum())\n",
    "print(\"Number of NaN price:\", df[\"Date\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4be6b7",
   "metadata": {},
   "source": [
    "We use arithmetic return because it is the most accurate indicator for measuring the actual loss in value of a single asset over a short time horizon (1 day).\n",
    "\n",
    "$$R_t = \\frac{P_t - P_{t-1}}{P_{t-1}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2e8e66c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "      <th>return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>5.424</td>\n",
       "      <td>-0.035047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>5.329</td>\n",
       "      <td>-0.017515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-07</td>\n",
       "      <td>5.224</td>\n",
       "      <td>-0.019704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>5.453</td>\n",
       "      <td>0.043836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>5.340</td>\n",
       "      <td>-0.020723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>2018-12-21</td>\n",
       "      <td>4.045</td>\n",
       "      <td>-0.001481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>2018-12-24</td>\n",
       "      <td>4.010</td>\n",
       "      <td>-0.008653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>2018-12-27</td>\n",
       "      <td>3.938</td>\n",
       "      <td>-0.017955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>2018-12-28</td>\n",
       "      <td>4.088</td>\n",
       "      <td>0.038090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>4.119</td>\n",
       "      <td>0.007583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1022 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  Price    return\n",
       "1    2015-01-05  5.424 -0.035047\n",
       "2    2015-01-06  5.329 -0.017515\n",
       "3    2015-01-07  5.224 -0.019704\n",
       "4    2015-01-08  5.453  0.043836\n",
       "5    2015-01-09  5.340 -0.020723\n",
       "...         ...    ...       ...\n",
       "1018 2018-12-21  4.045 -0.001481\n",
       "1019 2018-12-24  4.010 -0.008653\n",
       "1020 2018-12-27  3.938 -0.017955\n",
       "1021 2018-12-28  4.088  0.038090\n",
       "1022 2018-12-31  4.119  0.007583\n",
       "\n",
       "[1022 rows x 3 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"return\"]=df[\"Price\"].pct_change() \n",
    "df = df.iloc[1:] #Del the Nan values of the first row\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f8de7fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Date  Price    return\n",
      "508 2016-12-23  5.376 -0.008118\n",
      "509 2016-12-27  5.380  0.000744\n",
      "510 2016-12-28  5.379 -0.000186\n",
      "511 2016-12-29  5.328 -0.009481\n",
      "512 2016-12-30  5.360  0.006006\n"
     ]
    }
   ],
   "source": [
    "# We select the daily prices of the stock Natixis between January 2015 and December 2016 for question a\n",
    "df_a =df[(df[\"Date\"]>=\"2015-01-01\") & (df[\"Date\"]<=\"2016-12-31\")] \n",
    "print(df_a.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7326ee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probability of level alpha (1-alpha*100) \n",
    "alpha=0.05 #For alpha=0.05, the probability level is 1-0.05*100=95%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b17ef8",
   "metadata": {},
   "source": [
    "To calculate the VaR, we need the estimated cumulative distribution function $\\hat{F}(x)$. According to the course:\n",
    "\n",
    "\n",
    "$$\\hat{F}(x) = \\frac{1}{n} \\sum_{i=1}^{n} \\mathcal{K} \\left( \\frac{x - X_i}{h} \\right)$$\n",
    "\n",
    "\n",
    "Where $$\\mathcal{K}(u) = \\int_{-\\infty}^{u} K(t) dt$$ is the kernel integral. For the Biweight kernel:\n",
    "\n",
    "\n",
    "* If $u < -1$: $\\mathcal{K}(u) = 0$\n",
    "* If $u > 1$: $\\mathcal{K}(u) = 1$\n",
    "* If $u \\in [-1, 1]$:\n",
    "\n",
    "And $$K(t) = \\frac{15}{16}(1 - t^2)^2 \\mathbb{1}_{|t| \\leq 1}$$\n",
    "\n",
    "\n",
    "\n",
    "Thus $$\\mathcal{K}(u) = \\int_{-1}^{u} \\frac{15}{16}(1 - 2t^2 + t^4) dt = \\frac{1}{2} + \\frac{15}{16} \\left( u - \\frac{2}{3}u^3 + \\frac{1}{5}u^5 \\right)$$\n",
    "\n",
    "\n",
    "The VaR at level $\\alpha$ is then the value $x$ such that $\\hat{F}(x) = \\alpha$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "059d5687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of the Biweight kernel integral from -inf to u\n",
    "def K(u):\n",
    "    if u<-1:\n",
    "        return 0\n",
    "    if u>1:\n",
    "        return 1\n",
    "    return 0.5+(15/16)*(u-(2/3)*(u**3)+(1/5)*(u**5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce769d8",
   "metadata": {},
   "source": [
    "The choice of the bandwidth parameter $h$ is crucial as it determines the bias-variance tradeoff of our estimator:\n",
    "\n",
    "* A bandwidth that is too small leads to a distribution that is too close to the historical data.\n",
    "* A bandwidth that is too large smooths out the specific features of the distribution.\n",
    "\n",
    "In this project, we could use Silverman‚Äôs rule of thumb as a starting point, but it was originally calibrated for a Gaussian kernel:\n",
    "\n",
    "$$h_{Silverman} = 1.06 \\cdot \\hat{\\sigma} \\cdot n^{-1/5}$$\n",
    "\n",
    "Thus, to remain consistent with the course, we will use **$h = 0.003$**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "46158286",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = 0.003\n",
    "#Estimation of the CDF\n",
    "def F(x,rend):\n",
    "    u=(x-rend)/h\n",
    "    somme=sum(K(val) for val in u)\n",
    "    return somme/len(rend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "12561245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaR Non-parametric at 95.0% = 3.86%\n"
     ]
    }
   ],
   "source": [
    "#We use a dichotomy algorithm to calculate VaR such that F(VaR) = alpha\n",
    "def dichotomie(rend,alpha):\n",
    "    a=-1\n",
    "    b=1\n",
    "    eps=1e-9\n",
    "    while abs(b - a)>eps:\n",
    "        m = (a + b)/2\n",
    "        if F(m,rend) == 1-alpha:\n",
    "            return m\n",
    "        elif F(m,rend) < 1-alpha:\n",
    "            a = m\n",
    "        else:\n",
    "            b = m\n",
    "    return (a + b)/ 2\n",
    "\n",
    "Var_Nonpara= dichotomie(df_a[\"return\"], alpha)\n",
    "print(f\"VaR Non-parametric at {100-alpha*100}% = {Var_Nonpara:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0d4d15",
   "metadata": {},
   "source": [
    "So we are sure at 95% (1-alpha*100%) to not lose more than 3.86% at one-day horizon. \n",
    "As we use a biweight kernel with a bandwidth of h=0.003 (course material) on the 2015-2016 period, it provides a smoothed estimation of the lower tail of the return distribution. \n",
    "In contrast to the empirical quantile method, this non-parametric approach leverages the local density of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2131ca0",
   "metadata": {},
   "source": [
    ">b ‚Äì Which proportion of price returns between January 2017 and December 2018 does exceed the VaR\n",
    "threshold defined in the previous question? Do you validate the choice of this non-parametric VaR?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526227f",
   "metadata": {},
   "source": [
    "We first calculate the returns for the test period. Then, we count how many of these returns $R_t$ satisfy the condition:\n",
    "\n",
    "$$R_t < -VaR_{1-\\alpha}$$\n",
    "\n",
    "where $VaR_{1-\\alpha}$ is the positive value calculated in part (a).\n",
    "The proportion of exceptions $\\hat{p}$ is given by:\n",
    "\n",
    "$$\\hat{p} = \\frac{1}{N_{test}} \\sum_{t=1}^{N_{test}} \\mathbb{1}_{\\{R_t < -VaR_{1-\\alpha}\\}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "be4aee0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of returns exceeding VaR is : 1.57%\n"
     ]
    }
   ],
   "source": [
    "#Test dataset to validate or not the choice of the VaR\n",
    "df_b = df[(df[\"Date\"] >= \"2017-01-01\") & (df[\"Date\"] <= \"2018-12-31\")]\n",
    "#We use -Var_Nonpara because Var_Nonpara is the positive loss\n",
    "exceeding_returns=df_b[df_b[\"return\"]< -Var_Nonpara]\n",
    "proportion = len(exceeding_returns)/len(df_b)\n",
    "print(f\"The proportion of returns exceeding VaR is : {proportion:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74fe0426",
   "metadata": {},
   "source": [
    "We observe that 1.57%<5%. This means that in the 2017-2018 period, the losses exceeded the 2015-2016 risk estimate significantly less often than predicted.\n",
    "Thus, the model is conservative because as we can see, it overestimates the actual risk encountered in 2017-2018.\n",
    "\n",
    "To conclude, we partially validate the choice. Indeed, the model is safe (no underestimation of risk), but it lacks efficiency as it provides a threshold that is too high for the actual market conditions. \n",
    "\n",
    "We suggest to use a weighted historical VaR or an adaptive bandwidth as seen in the course to give more importance to recent observations and better adapt to the change of regimes in the market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6630a22",
   "metadata": {},
   "source": [
    " ### **Question B | Expected shortfall**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc872db9",
   "metadata": {},
   "source": [
    ">Calculate the expected shortfall for the VaR calculated in question A. How is the result, compared to the VaR?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7dae86",
   "metadata": {},
   "source": [
    "To be consistent with the previous questions, we will not calculate the ES using a simple empirical average, but using the same probability density as before.\n",
    "The kernel smooths out the effects of isolated extreme values to obtain a more robust measurement.\n",
    "\n",
    "We defined the Expected Shortfall (ES) as:\n",
    "\n",
    "$$ES_{\\alpha} = \\frac{1}{\\alpha} \\int_{-\\infty}^{q_{\\alpha}} x \\hat{f}(x) dx$$\n",
    "\n",
    "Using our biweight kernel estimator, we can simplifies this integral to a weighted sum:\n",
    "\n",
    "$$ES_{returns} = \\frac{1}{n \\alpha} \\sum_{i=1}^{n} \\left[ X_i \\mathcal{K}(u_i) + h J(u_i) \\right]$$\n",
    "\n",
    "Where:\n",
    "\n",
    "* $u_i = \\frac{q_{\\alpha} - X_i}{h}$\n",
    "* $\\mathcal{K}(u)$ is the kernel integral (already implemented for the VaR calculation)\n",
    "* $J(u) = \\int_{-1}^{u} t K(t) dt$ is the first moment of the kernel\n",
    "\n",
    "For the biweight kernel, the moment primitive is:\n",
    "\n",
    "$$J(u) = \\frac{15}{16} \\left( \\frac{1}{2}u^2 - \\frac{1}{2}u^4 + \\frac{1}{6}u^6 - \\frac{1}{6} \\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588e4592",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculation of the moment primitive for the biweight kernel\n",
    "def J(u):\n",
    "    if u<-1 or u>1:  # The integral over the entire support of a symmetric kernel = 0\n",
    "        return 0\n",
    "    return (15/16)*(0.5*u**2-0.5*u**4+(1/6)*u**6-1/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1787d5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Shortfall: 5.23%\n"
     ]
    }
   ],
   "source": [
    "# Expected Shortfall calculation\n",
    "def ES(rend):  #rend is the array of historical returns \n",
    "    n=len(rend)\n",
    "    #Var_Nonpara has to be the negative quantile\n",
    "    u=(-Var_Nonpara-rend)/h  #u is the standardized distance between the qunatile and each historical observation\n",
    "    XK=rend*np.array([K(i) for i in u]) #return weighted by the cumulative probability of the kernel\n",
    "    hJ=h*np.array([J(i) for i in u])\n",
    "    es_return=np.mean(XK + hJ)/alpha # ES formula for a kernel estimator(explained above)\n",
    "    return -es_return    # The loss has to be >0\n",
    "\n",
    "ES_Nonpara = ES(df_a[\"return\"])\n",
    "print(f\"Expected Shortfall: {ES_Nonpara:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63da6ab",
   "metadata": {},
   "source": [
    "The Expected Shortfall (5.23%) is higher than the VaR (3.86%). This result was expected since the ES measures the average of all losses in the tail of the distribution, and not just the cut-off point.\n",
    "\n",
    "The ES/VaR ratio here is approximately 1.41. This indicates the danger of tail risk. Indeed, if returns were perfectly normal, this ratio would be lower. The biweight kernel therefore better captures the risk of extreme losses specific to the stock, which VaR alone does not take into account."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
